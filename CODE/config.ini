########################################################
# The following settings are for Logicytics as a whole #
########################################################

[Settings]
# Would you like to enable debug mode?
# This will print out more information to the console, with prefix DEBUG
# This will not be logged however
log_using_debug = false

# Would you like for new logs to be created every execution?
# Or would you like to append to the same log file?
delete_old_logs = false

# When using threading mode, you have the option to decide how many threads to use (workers)
# Uncomment and change the value to use a maximum amount of threads,
# otherwise keep it commented if you don't need a maximum limit
; max_workers = 10

# Logicytics will save preferences and history in a file,
# This is used by Flag.py, to suggest better flags
# Would you like this to happen?
# This is recommended, as it will improve the suggestions - Data will never be shared
save_preferences = true

[System Settings]
# Do not play with these settings unless you know what you are doing
# Dev Mode allows a safe way to modify these settings!!
version = 3.4.1
files = "bluetooth_details.py, bluetooth_logger.py, browser_miner.ps1, cmd_commands.py, config.ini, dir_list.py, dump_memory.py, event_log.py, Logicytics.py, log_miner.py, media_backup.py, netadapter.ps1, network_psutil.py, packet_sniffer.py, property_scraper.ps1, registry.py, sensitive_data_miner.py, ssh_miner.py, sys_internal.py, tasklist.py, tree.ps1, vulnscan.py, wifi_stealer.py, window_feature_miner.ps1, wmic.py, logicytics\Checks.py, logicytics\Config.py, logicytics\Execute.py, logicytics\FileManagement.py, logicytics\Flag.py, logicytics\Get.py, logicytics\Logger.py, logicytics\User_History.json.gz, VulnScan\Model SenseMini .3n3.pth, VulnScan\README.md, VulnScan\Vectorizer .3n3.pkl"

########################################################
#   The following settings are for specific modules    #
########################################################

[Flag Settings]
# The minimum accuracy to suggest a flag,
# This is a percentage, and must be a float
# The default is 30.0, and is what we advise
# If the accuracy is below this, the flag will move to the next suggestion process
# The process is: difflib, then model, then history suggestions
# Make sure to keep between 0.0 and 100.0
accuracy_min = 30.0

# This is the model to use to suggest flags,
# I advise to keep it as all-MiniLM-L6-v2
# This is the best model for this task, and is lightweight
# The model MUST be a Sentence Transformer model
model_to_use = all-MiniLM-L6-v2

# Finally, should debug mode be enabled for the flag module?
# This will print out more information to the console,
# This is for the model itself, and is based on tqdm, it shows extra info on batches
# As well as more information on behind the scenes
model_debug = false

###################################################

[DumpMemory Settings]
# If the file size generated exceeds this limit,
# the file will be truncated with a message
# Put 0 to disable the limit - Limit is in MiB - int
file_size_limit = 0
# Safety margin to check, it multiplies with the size limit
# This makes sure that after the file is created, there is still
# disk space left for other tasks,
# Make sure its above 1 or else it will fail
# Put 1 to disable the limit - Limit is in MiB - float
file_size_safety = 1.5

###################################################

[NetWorkPsutil Settings]
# Total time this will take will be `sample_count * interval`

# Number of samples to take for feature `measure network bandwidth usage`
# This is an integer, and should be 1 and above
sample_count = 5
# Time between samples in seconds for feature `measure network bandwidth usage`
# This is a float, and should be above 0
interval = 1.5

###################################################

[PacketSniffer Settings]
# The interface to sniff packets on, keep it as WiFi for most cases
# Autocorrects between WiFi and Wi-Fi
interface = WiFi
# The number of packets to sniff,
# Must be greater than or equal to 1 - int
packet_count = 5000
# The time to timeout the sniffing process only,
# Must be greater than or equal to 5 - int
timeout = 10
# The maximum retry time for the whole process,
# Must be greater than or equal to 10 and timeout - int
max_retry_time = 30

###################################################

[VulnScan.generate Settings]
# The following settings are for the Generate module for fake training data
extensions = .txt, .log, .md, .csv, .json, .xml, .html, .yaml, .ini, .pdf, .docx, .xlsx, .pptx
save_path = PATH

# Options include:
# 'Sense' - Generates 50k files, each 25KB in size.
# 'SenseNano' - Generates 5 files, each 5KB in size.
# 'SenseMacro' - Generates 1m files, each 10KB in size.
# 'SenseMini' - Generates 10k files, each 10KB in size.
# 'SenseCustom' - Uses custom size settings from the configuration file.
code_name = SenseMini

# This allows more randomness in the file sizes, use 0 to disable
# this is applied randomly every time a file is generated
# Variation is applied in the following way:
# size +- (size */ variation) where its random weather to add or subtract and divide or multiply
size_variation = 0.1

# Set to SenseCustom to use below size settings
min_file_size = 5KB
max_file_size = 50KB

# Chances for the following data types in files:
# 0.0 - 1.0, the rest will be for pure data
full_sensitive_chance = 0.07
partial_sensitive_chance = 0.2

[VulnScan.vectorizer Settings]
# The following settings are for the Vectorizer module for vectorizing data
# Usually it automatically vectorizes data, but this is for manual vectorization

# We advise to use this vectorization, although not knowing the vectorizer is not advised
# as this may lead to ValueErrors due to different inputs
# Use the vectorizer supplied for any v3 model on SenseMini

# The path to the data to vectorize, either a file or a directory
data_path = PATH
# The path to save the vectorized data - It will automatically be appended '\Vectorizer.pkl'
# Make sure the path is a directory, and it exists
output_path = PATH

# Vectorizer to use, options include:
# tfidf or count - The code for the training only supports tfidf - we advise to use tfidf
vectorizer_type = tfidf

[VulnScan.train Settings]
# The following settings are for the Train module for training models
# NeuralNetwork seems to be the best choice for this task
# Options: "NeuralNetwork", "LogReg",
#          "RandomForest", "ExtraTrees", "GBM",
#          "XGBoost", "DecisionTree", "NaiveBayes"
model_name = NeuralNetwork

# General Training Parameters
epochs = 10
batch_size = 32
learning_rate = 0.001
use_cuda = true

# Paths to train and save data
train_data_path = PATH
# If all models are to be trained, this is the path to save all models,
# and will be appended with the model codename and follow naming convention
save_model_path = PATH

[VulnScan.study Settings]
# Here is the basics of the study module
# This is useful to generate graphs and data that may help in understanding the model
# Everything is found online pre-studied, so this is not necessary
# But it is useful for understanding the model locally
# All files be saved here, and can't be changed, PATH is "NN features/"

# This is the path to the model, and the vectorizer
model_path = PATH
vectorizer_path = PATH
# Number of features to visualise in the SVG Bar graph, maximum is 3000 due to limitations
# Placing -1 will visualise first 3000 features. Bar will be a color gradient heatmap.
number_of_features = -1

##################################################
